{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Welcome to Jupyter Notebook and Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For many of you, this will be your first time \"programming,\" at least in a traditional language, though you likely have used similar ideas and concepts in constructing Excel worksheets, particularly if you use VBA. While the idea of programming may be intimidating, modern tools and software have made it very accessible. For example, you may have had visions of strings of ones and zeros scrolling by Matrix fashion as you program, but the reality is that most of programming (particularly in data science) looks like constructing mathematical formulae using something approaching natural language.\n",
    "\n",
    "We are going to be using the programming language **Python** for this exercise, the standard programming language in data science. We will also be using several auxillary industry standard packages that are commonly used in the data science workflow.\n",
    "\n",
    "The interface that we are using is a *Jupyter Notebook*. This is a piece of software that can run either locally on your own computer or on a server in the cloud, but either way you access it through your browser. It provides a user friendly interface to work with Python as well as other programming languages commonly used in data science workflows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A Jupyter Notebook consists of *cells* which can either contain Python code or written text/images. What you are reading now is the latter kind of cell. You progress through a Jupyter Notebook by *running* the code cells, which just executes the code in that cell. The below image show the difference between the two:\n",
    "\n",
    "<img src=\"images/1 - Starting Jupyter Notebook.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "When a cell has run, you will know it worked because their will now be a number next to the code cell:\n",
    "\n",
    "<img src=\"images/4 - Number from Code Cell.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "For this exercise, we will primarily be using some user interface controls that I have built to make things a little more accessible. You will need to run the code in order to get the controls to show up, and the decisions you make will directly correspond to the common decisions that a data scientist must make when analyzing a data set. This will allow you to progress with no knowledge of programming."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Instead of running all the cells one by one, this notebook has been set up for you to run the entire notebook and then just interact with the controls I have built. To do this, you will click on \"Run\" in the toolbar and then click on \"Run all Cells\". See picture below:\n",
    "\n",
    "<img src=\"images/Run all cells.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You will know this worked because you will see numbers next to all of the code cells. From here on out, you shouldn't need to run any additional cells. Just go through the notebook and the interactive components should be obvious.\n",
    "\n",
    "**If something seems broken or hung up with the notebook, you can use the option \"Restart Kernel and Run All Cells...\" displayed in the image above to completely reset the notebook (but you will have to start again).** One way in which this might happen is if you choose too many variables when training a model (the logistic regression will take a long time to finish if you have more than a 1000 columns, this will make sense shortly). If something is taking forever to run, \"Restart Kernel and Run All Cells...\" will fix the problem, but you will have to recreate your data set.\n",
    "\n",
    "Good luck, data scientist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "At it's core, Python is a relatively simple set of operations that define the *programming language*. You can use these *primitives* to build more complicated functionality. While this is powerful, it is also very complicated, so fortunately, we do not have to do this ourselves!\n",
    "\n",
    "Instead, we will be using *open source* software (i.e. software that has been written and freely distributed by a mixture of volunteers and companies that use the software and contribute to it's development) that adds in additional functionality. This software, while it is free, is also industry standard, and much of a typical data science \"software stack\" used in large companies will consist of open source software, much of which we will be using for this exercise.\n",
    "\n",
    "This software is *imported*, i.e. made available for us to use, and this is what we are doing below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import OneHotEncoder, FunctionTransformer, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# %matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import datetime\n",
    "import itertools as it\n",
    "import dill\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interactive, interactive_output, fixed, interact_manual, HBox, VBox, Layout\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Load and reshape the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The *sine qua non* of data science, is unsurprisingly, the data! However, in order to work with the data, we must *load* the data. Typically, we start with a *csv* (or comma separated values) file. This can be exported from an excel sheet. You can also connect directly to databases and load data direct from databases. For the purpose of this exercise, we will be using the \"training.csv\" file for training data for Carvana. Below we are going to be loading the data and reshaping it into a more useable form.\n",
    "\n",
    "First, we will load in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How big is our dataset? It is always good to have a handle on the size before attempting any analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65684, 34)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The first number above is the number of rows, and the second number is the number of columns. This is both a long (many rows) and wide (many columns) dataset, though it is not extreme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Before diving in, it's good to see what the data actually looks like. Below is the first 10 rows of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RefId</th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>Color</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>WheelTypeID</th>\n",
       "      <th>WheelType</th>\n",
       "      <th>VehOdo</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Size</th>\n",
       "      <th>TopThreeAmericanName</th>\n",
       "      <th>MMRAcquisitionAuctionAveragePrice</th>\n",
       "      <th>MMRAcquisitionAuctionCleanPrice</th>\n",
       "      <th>MMRAcquisitionRetailAveragePrice</th>\n",
       "      <th>MMRAcquisitonRetailCleanPrice</th>\n",
       "      <th>MMRCurrentAuctionAveragePrice</th>\n",
       "      <th>MMRCurrentAuctionCleanPrice</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>1500 RAM PICKUP 2WD</td>\n",
       "      <td>ST</td>\n",
       "      <td>QUAD CAB 4.7L SLT</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>93593</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>LARGE TRUCK</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>6854.0</td>\n",
       "      <td>8383.0</td>\n",
       "      <td>10897.0</td>\n",
       "      <td>12572.0</td>\n",
       "      <td>7456.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>11374.0</td>\n",
       "      <td>12791.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>STRATUS V6</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN SXT FFV</td>\n",
       "      <td>MAROON</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>73807</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>3202.0</td>\n",
       "      <td>4760.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>8457.0</td>\n",
       "      <td>4035.0</td>\n",
       "      <td>5557.0</td>\n",
       "      <td>7146.0</td>\n",
       "      <td>8702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>NEON</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>65617</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>4658.0</td>\n",
       "      <td>5690.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>5518.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FOCUS</td>\n",
       "      <td>ZX3</td>\n",
       "      <td>2D COUPE ZX3</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>69367</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>FORD</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>7723.0</td>\n",
       "      <td>8707.0</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>4384.0</td>\n",
       "      <td>6739.0</td>\n",
       "      <td>7911.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>GALANT 4C</td>\n",
       "      <td>ES</td>\n",
       "      <td>4D SEDAN ES</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>81054</td>\n",
       "      <td>OTHER ASIAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>3901.0</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>6706.0</td>\n",
       "      <td>8577.0</td>\n",
       "      <td>4709.0</td>\n",
       "      <td>5827.0</td>\n",
       "      <td>8149.0</td>\n",
       "      <td>9451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>KIA</td>\n",
       "      <td>SPECTRA</td>\n",
       "      <td>EX</td>\n",
       "      <td>4D SEDAN EX</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>65328</td>\n",
       "      <td>OTHER ASIAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>2966.0</td>\n",
       "      <td>4038.0</td>\n",
       "      <td>6240.0</td>\n",
       "      <td>8496.0</td>\n",
       "      <td>2980.0</td>\n",
       "      <td>4115.0</td>\n",
       "      <td>6230.0</td>\n",
       "      <td>8603.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>FORD</td>\n",
       "      <td>TAURUS</td>\n",
       "      <td>SE</td>\n",
       "      <td>4D SEDAN SE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>65805</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>FORD</td>\n",
       "      <td>3313.0</td>\n",
       "      <td>4342.0</td>\n",
       "      <td>6667.0</td>\n",
       "      <td>7707.0</td>\n",
       "      <td>3713.0</td>\n",
       "      <td>4578.0</td>\n",
       "      <td>6942.0</td>\n",
       "      <td>8242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>KIA</td>\n",
       "      <td>SPECTRA</td>\n",
       "      <td>EX</td>\n",
       "      <td>4D SEDAN EX</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>49921</td>\n",
       "      <td>OTHER ASIAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>6196.0</td>\n",
       "      <td>7274.0</td>\n",
       "      <td>9687.0</td>\n",
       "      <td>10624.0</td>\n",
       "      <td>6417.0</td>\n",
       "      <td>7371.0</td>\n",
       "      <td>9637.0</td>\n",
       "      <td>10778.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21973</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>12/14/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>GMC</td>\n",
       "      <td>1500 SIERRA PICKUP 2</td>\n",
       "      <td>SLE</td>\n",
       "      <td>REG CAB 4.3L</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>80080</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>LARGE TRUCK</td>\n",
       "      <td>GM</td>\n",
       "      <td>5243.0</td>\n",
       "      <td>6627.0</td>\n",
       "      <td>8848.0</td>\n",
       "      <td>10458.0</td>\n",
       "      <td>5712.0</td>\n",
       "      <td>7552.0</td>\n",
       "      <td>9494.0</td>\n",
       "      <td>11663.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5546</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>5500.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>12/14/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>FORD</td>\n",
       "      <td>F150 PICKUP 2WD V6</td>\n",
       "      <td>XL</td>\n",
       "      <td>REG CAB 4.2L XL</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>75419</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>LARGE TRUCK</td>\n",
       "      <td>FORD</td>\n",
       "      <td>3168.0</td>\n",
       "      <td>4320.0</td>\n",
       "      <td>5826.0</td>\n",
       "      <td>6762.0</td>\n",
       "      <td>2871.0</td>\n",
       "      <td>3822.0</td>\n",
       "      <td>5734.0</td>\n",
       "      <td>6559.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5546</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>5300.0</td>\n",
       "      <td>0</td>\n",
       "      <td>869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RefId  IsBadBuy   PurchDate Auction  VehYear  VehicleAge        Make  \\\n",
       "0      2         0   12/7/2009   ADESA     2004           5       DODGE   \n",
       "1      3         0   12/7/2009   ADESA     2005           4       DODGE   \n",
       "2      4         0   12/7/2009   ADESA     2004           5       DODGE   \n",
       "3      5         0   12/7/2009   ADESA     2005           4        FORD   \n",
       "4      6         0   12/7/2009   ADESA     2004           5  MITSUBISHI   \n",
       "5      7         0   12/7/2009   ADESA     2004           5         KIA   \n",
       "6      8         0   12/7/2009   ADESA     2005           4        FORD   \n",
       "7      9         0   12/7/2009   ADESA     2007           2         KIA   \n",
       "8     11         0  12/14/2009   ADESA     2005           4         GMC   \n",
       "9     12         0  12/14/2009   ADESA     2001           8        FORD   \n",
       "\n",
       "                  Model Trim           SubModel   Color Transmission  \\\n",
       "0   1500 RAM PICKUP 2WD   ST  QUAD CAB 4.7L SLT   WHITE         AUTO   \n",
       "1            STRATUS V6  SXT   4D SEDAN SXT FFV  MAROON         AUTO   \n",
       "2                  NEON  SXT           4D SEDAN  SILVER         AUTO   \n",
       "3                 FOCUS  ZX3       2D COUPE ZX3  SILVER       MANUAL   \n",
       "4             GALANT 4C   ES        4D SEDAN ES   WHITE         AUTO   \n",
       "5               SPECTRA   EX        4D SEDAN EX   BLACK         AUTO   \n",
       "6                TAURUS   SE        4D SEDAN SE   WHITE         AUTO   \n",
       "7               SPECTRA   EX        4D SEDAN EX   BLACK         AUTO   \n",
       "8  1500 SIERRA PICKUP 2  SLE       REG CAB 4.3L  SILVER         AUTO   \n",
       "9    F150 PICKUP 2WD V6   XL    REG CAB 4.2L XL   WHITE       MANUAL   \n",
       "\n",
       "   WheelTypeID WheelType  VehOdo  Nationality         Size  \\\n",
       "0          1.0     Alloy   93593     AMERICAN  LARGE TRUCK   \n",
       "1          2.0    Covers   73807     AMERICAN       MEDIUM   \n",
       "2          1.0     Alloy   65617     AMERICAN      COMPACT   \n",
       "3          2.0    Covers   69367     AMERICAN      COMPACT   \n",
       "4          2.0    Covers   81054  OTHER ASIAN       MEDIUM   \n",
       "5          2.0    Covers   65328  OTHER ASIAN       MEDIUM   \n",
       "6          2.0    Covers   65805     AMERICAN       MEDIUM   \n",
       "7          2.0    Covers   49921  OTHER ASIAN       MEDIUM   \n",
       "8          1.0     Alloy   80080     AMERICAN  LARGE TRUCK   \n",
       "9          1.0     Alloy   75419     AMERICAN  LARGE TRUCK   \n",
       "\n",
       "  TopThreeAmericanName  MMRAcquisitionAuctionAveragePrice  \\\n",
       "0             CHRYSLER                             6854.0   \n",
       "1             CHRYSLER                             3202.0   \n",
       "2             CHRYSLER                             1893.0   \n",
       "3                 FORD                             3913.0   \n",
       "4                OTHER                             3901.0   \n",
       "5                OTHER                             2966.0   \n",
       "6                 FORD                             3313.0   \n",
       "7                OTHER                             6196.0   \n",
       "8                   GM                             5243.0   \n",
       "9                 FORD                             3168.0   \n",
       "\n",
       "   MMRAcquisitionAuctionCleanPrice  MMRAcquisitionRetailAveragePrice  \\\n",
       "0                           8383.0                           10897.0   \n",
       "1                           4760.0                            6943.0   \n",
       "2                           2675.0                            4658.0   \n",
       "3                           5054.0                            7723.0   \n",
       "4                           4908.0                            6706.0   \n",
       "5                           4038.0                            6240.0   \n",
       "6                           4342.0                            6667.0   \n",
       "7                           7274.0                            9687.0   \n",
       "8                           6627.0                            8848.0   \n",
       "9                           4320.0                            5826.0   \n",
       "\n",
       "   MMRAcquisitonRetailCleanPrice  MMRCurrentAuctionAveragePrice  \\\n",
       "0                        12572.0                         7456.0   \n",
       "1                         8457.0                         4035.0   \n",
       "2                         5690.0                         1844.0   \n",
       "3                         8707.0                         3247.0   \n",
       "4                         8577.0                         4709.0   \n",
       "5                         8496.0                         2980.0   \n",
       "6                         7707.0                         3713.0   \n",
       "7                        10624.0                         6417.0   \n",
       "8                        10458.0                         5712.0   \n",
       "9                         6762.0                         2871.0   \n",
       "\n",
       "   MMRCurrentAuctionCleanPrice  MMRCurrentRetailAveragePrice  \\\n",
       "0                       9222.0                       11374.0   \n",
       "1                       5557.0                        7146.0   \n",
       "2                       2646.0                        4375.0   \n",
       "3                       4384.0                        6739.0   \n",
       "4                       5827.0                        8149.0   \n",
       "5                       4115.0                        6230.0   \n",
       "6                       4578.0                        6942.0   \n",
       "7                       7371.0                        9637.0   \n",
       "8                       7552.0                        9494.0   \n",
       "9                       3822.0                        5734.0   \n",
       "\n",
       "   MMRCurrentRetailCleanPrice PRIMEUNIT AUCGUART  BYRNO  VNZIP1 VNST  \\\n",
       "0                     12791.0       NaN      NaN  19638   33619   FL   \n",
       "1                      8702.0       NaN      NaN  19638   33619   FL   \n",
       "2                      5518.0       NaN      NaN  19638   33619   FL   \n",
       "3                      7911.0       NaN      NaN  19638   33619   FL   \n",
       "4                      9451.0       NaN      NaN  19638   33619   FL   \n",
       "5                      8603.0       NaN      NaN  19638   33619   FL   \n",
       "6                      8242.0       NaN      NaN  19638   33619   FL   \n",
       "7                     10778.0       NaN      NaN  21973   33619   FL   \n",
       "8                     11663.0       NaN      NaN   5546   33619   FL   \n",
       "9                      6559.0       NaN      NaN   5546   33619   FL   \n",
       "\n",
       "   VehBCost  IsOnlineSale  WarrantyCost  \n",
       "0    7600.0             0          1053  \n",
       "1    4900.0             0          1389  \n",
       "2    4100.0             0           630  \n",
       "3    4000.0             0          1020  \n",
       "4    5600.0             0           594  \n",
       "5    4200.0             0           533  \n",
       "6    4500.0             0           825  \n",
       "7    5600.0             0           482  \n",
       "8    5500.0             0          1373  \n",
       "9    5300.0             0           869  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', 200):\n",
    "    display(df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Note that there is a column for 'RefId' in the data set, that is just an internal column referencing the row. It is not necessary and will provide no predictive value, so we will get rid of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false,
    "editable": false,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>Color</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>WheelTypeID</th>\n",
       "      <th>WheelType</th>\n",
       "      <th>VehOdo</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Size</th>\n",
       "      <th>TopThreeAmericanName</th>\n",
       "      <th>MMRAcquisitionAuctionAveragePrice</th>\n",
       "      <th>MMRAcquisitionAuctionCleanPrice</th>\n",
       "      <th>MMRAcquisitionRetailAveragePrice</th>\n",
       "      <th>MMRAcquisitonRetailCleanPrice</th>\n",
       "      <th>MMRCurrentAuctionAveragePrice</th>\n",
       "      <th>MMRCurrentAuctionCleanPrice</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>1500 RAM PICKUP 2WD</td>\n",
       "      <td>ST</td>\n",
       "      <td>QUAD CAB 4.7L SLT</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>93593</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>LARGE TRUCK</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>6854.0</td>\n",
       "      <td>8383.0</td>\n",
       "      <td>10897.0</td>\n",
       "      <td>12572.0</td>\n",
       "      <td>7456.0</td>\n",
       "      <td>9222.0</td>\n",
       "      <td>11374.0</td>\n",
       "      <td>12791.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>7600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>STRATUS V6</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN SXT FFV</td>\n",
       "      <td>MAROON</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>73807</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>3202.0</td>\n",
       "      <td>4760.0</td>\n",
       "      <td>6943.0</td>\n",
       "      <td>8457.0</td>\n",
       "      <td>4035.0</td>\n",
       "      <td>5557.0</td>\n",
       "      <td>7146.0</td>\n",
       "      <td>8702.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>DODGE</td>\n",
       "      <td>NEON</td>\n",
       "      <td>SXT</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>65617</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>1893.0</td>\n",
       "      <td>2675.0</td>\n",
       "      <td>4658.0</td>\n",
       "      <td>5690.0</td>\n",
       "      <td>1844.0</td>\n",
       "      <td>2646.0</td>\n",
       "      <td>4375.0</td>\n",
       "      <td>5518.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4100.0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>FORD</td>\n",
       "      <td>FOCUS</td>\n",
       "      <td>ZX3</td>\n",
       "      <td>2D COUPE ZX3</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>MANUAL</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>69367</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>COMPACT</td>\n",
       "      <td>FORD</td>\n",
       "      <td>3913.0</td>\n",
       "      <td>5054.0</td>\n",
       "      <td>7723.0</td>\n",
       "      <td>8707.0</td>\n",
       "      <td>3247.0</td>\n",
       "      <td>4384.0</td>\n",
       "      <td>6739.0</td>\n",
       "      <td>7911.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>4000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>12/7/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>MITSUBISHI</td>\n",
       "      <td>GALANT 4C</td>\n",
       "      <td>ES</td>\n",
       "      <td>4D SEDAN ES</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Covers</td>\n",
       "      <td>81054</td>\n",
       "      <td>OTHER ASIAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>3901.0</td>\n",
       "      <td>4908.0</td>\n",
       "      <td>6706.0</td>\n",
       "      <td>8577.0</td>\n",
       "      <td>4709.0</td>\n",
       "      <td>5827.0</td>\n",
       "      <td>8149.0</td>\n",
       "      <td>9451.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19638</td>\n",
       "      <td>33619</td>\n",
       "      <td>FL</td>\n",
       "      <td>5600.0</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsBadBuy  PurchDate Auction  VehYear  VehicleAge        Make  \\\n",
       "0         0  12/7/2009   ADESA     2004           5       DODGE   \n",
       "1         0  12/7/2009   ADESA     2005           4       DODGE   \n",
       "2         0  12/7/2009   ADESA     2004           5       DODGE   \n",
       "3         0  12/7/2009   ADESA     2005           4        FORD   \n",
       "4         0  12/7/2009   ADESA     2004           5  MITSUBISHI   \n",
       "\n",
       "                 Model Trim           SubModel   Color Transmission  \\\n",
       "0  1500 RAM PICKUP 2WD   ST  QUAD CAB 4.7L SLT   WHITE         AUTO   \n",
       "1           STRATUS V6  SXT   4D SEDAN SXT FFV  MAROON         AUTO   \n",
       "2                 NEON  SXT           4D SEDAN  SILVER         AUTO   \n",
       "3                FOCUS  ZX3       2D COUPE ZX3  SILVER       MANUAL   \n",
       "4            GALANT 4C   ES        4D SEDAN ES   WHITE         AUTO   \n",
       "\n",
       "   WheelTypeID WheelType  VehOdo  Nationality         Size  \\\n",
       "0          1.0     Alloy   93593     AMERICAN  LARGE TRUCK   \n",
       "1          2.0    Covers   73807     AMERICAN       MEDIUM   \n",
       "2          1.0     Alloy   65617     AMERICAN      COMPACT   \n",
       "3          2.0    Covers   69367     AMERICAN      COMPACT   \n",
       "4          2.0    Covers   81054  OTHER ASIAN       MEDIUM   \n",
       "\n",
       "  TopThreeAmericanName  MMRAcquisitionAuctionAveragePrice  \\\n",
       "0             CHRYSLER                             6854.0   \n",
       "1             CHRYSLER                             3202.0   \n",
       "2             CHRYSLER                             1893.0   \n",
       "3                 FORD                             3913.0   \n",
       "4                OTHER                             3901.0   \n",
       "\n",
       "   MMRAcquisitionAuctionCleanPrice  MMRAcquisitionRetailAveragePrice  \\\n",
       "0                           8383.0                           10897.0   \n",
       "1                           4760.0                            6943.0   \n",
       "2                           2675.0                            4658.0   \n",
       "3                           5054.0                            7723.0   \n",
       "4                           4908.0                            6706.0   \n",
       "\n",
       "   MMRAcquisitonRetailCleanPrice  MMRCurrentAuctionAveragePrice  \\\n",
       "0                        12572.0                         7456.0   \n",
       "1                         8457.0                         4035.0   \n",
       "2                         5690.0                         1844.0   \n",
       "3                         8707.0                         3247.0   \n",
       "4                         8577.0                         4709.0   \n",
       "\n",
       "   MMRCurrentAuctionCleanPrice  MMRCurrentRetailAveragePrice  \\\n",
       "0                       9222.0                       11374.0   \n",
       "1                       5557.0                        7146.0   \n",
       "2                       2646.0                        4375.0   \n",
       "3                       4384.0                        6739.0   \n",
       "4                       5827.0                        8149.0   \n",
       "\n",
       "   MMRCurrentRetailCleanPrice PRIMEUNIT AUCGUART  BYRNO  VNZIP1 VNST  \\\n",
       "0                     12791.0       NaN      NaN  19638   33619   FL   \n",
       "1                      8702.0       NaN      NaN  19638   33619   FL   \n",
       "2                      5518.0       NaN      NaN  19638   33619   FL   \n",
       "3                      7911.0       NaN      NaN  19638   33619   FL   \n",
       "4                      9451.0       NaN      NaN  19638   33619   FL   \n",
       "\n",
       "   VehBCost  IsOnlineSale  WarrantyCost  \n",
       "0    7600.0             0          1053  \n",
       "1    4900.0             0          1389  \n",
       "2    4100.0             0           630  \n",
       "3    4000.0             0          1020  \n",
       "4    5600.0             0           594  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if 'RefId' in df:\n",
    "    df = df.drop(columns='RefId')\n",
    "with pd.option_context('display.max_columns', 200):\n",
    "    display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Let's also look at the last 5 rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsBadBuy</th>\n",
       "      <th>PurchDate</th>\n",
       "      <th>Auction</th>\n",
       "      <th>VehYear</th>\n",
       "      <th>VehicleAge</th>\n",
       "      <th>Make</th>\n",
       "      <th>Model</th>\n",
       "      <th>Trim</th>\n",
       "      <th>SubModel</th>\n",
       "      <th>Color</th>\n",
       "      <th>Transmission</th>\n",
       "      <th>WheelTypeID</th>\n",
       "      <th>WheelType</th>\n",
       "      <th>VehOdo</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Size</th>\n",
       "      <th>TopThreeAmericanName</th>\n",
       "      <th>MMRAcquisitionAuctionAveragePrice</th>\n",
       "      <th>MMRAcquisitionAuctionCleanPrice</th>\n",
       "      <th>MMRAcquisitionRetailAveragePrice</th>\n",
       "      <th>MMRAcquisitonRetailCleanPrice</th>\n",
       "      <th>MMRCurrentAuctionAveragePrice</th>\n",
       "      <th>MMRCurrentAuctionCleanPrice</th>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <th>AUCGUART</th>\n",
       "      <th>BYRNO</th>\n",
       "      <th>VNZIP1</th>\n",
       "      <th>VNST</th>\n",
       "      <th>VehBCost</th>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <th>WarrantyCost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>65679</th>\n",
       "      <td>0</td>\n",
       "      <td>12/2/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>FORD</td>\n",
       "      <td>EXPLORER 2WD V6</td>\n",
       "      <td>XLS</td>\n",
       "      <td>4D SUV 4.0L FFV XLS</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>82563</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MEDIUM SUV</td>\n",
       "      <td>FORD</td>\n",
       "      <td>4668.0</td>\n",
       "      <td>5714.0</td>\n",
       "      <td>5541.0</td>\n",
       "      <td>6671.0</td>\n",
       "      <td>6148.0</td>\n",
       "      <td>7521.0</td>\n",
       "      <td>9659.0</td>\n",
       "      <td>10944.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18881</td>\n",
       "      <td>30212</td>\n",
       "      <td>GA</td>\n",
       "      <td>7000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65680</th>\n",
       "      <td>0</td>\n",
       "      <td>12/2/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2006</td>\n",
       "      <td>3</td>\n",
       "      <td>KIA</td>\n",
       "      <td>SORENTO 2WD</td>\n",
       "      <td>EX</td>\n",
       "      <td>4D SPORT UTILITY EX</td>\n",
       "      <td>GOLD</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>65399</td>\n",
       "      <td>OTHER ASIAN</td>\n",
       "      <td>MEDIUM SUV</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>7843.0</td>\n",
       "      <td>9171.0</td>\n",
       "      <td>8970.0</td>\n",
       "      <td>10405.0</td>\n",
       "      <td>7652.0</td>\n",
       "      <td>9310.0</td>\n",
       "      <td>12148.0</td>\n",
       "      <td>14204.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18111</td>\n",
       "      <td>30212</td>\n",
       "      <td>GA</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65681</th>\n",
       "      <td>1</td>\n",
       "      <td>12/2/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2001</td>\n",
       "      <td>8</td>\n",
       "      <td>MERCURY</td>\n",
       "      <td>SABLE</td>\n",
       "      <td>GS</td>\n",
       "      <td>4D SEDAN GS</td>\n",
       "      <td>BLACK</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>45234</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>FORD</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>2993.0</td>\n",
       "      <td>2656.0</td>\n",
       "      <td>3732.0</td>\n",
       "      <td>2190.0</td>\n",
       "      <td>3055.0</td>\n",
       "      <td>4836.0</td>\n",
       "      <td>5937.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18111</td>\n",
       "      <td>30212</td>\n",
       "      <td>GA</td>\n",
       "      <td>4200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65682</th>\n",
       "      <td>0</td>\n",
       "      <td>12/2/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2007</td>\n",
       "      <td>2</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>MALIBU 4C</td>\n",
       "      <td>LS</td>\n",
       "      <td>4D SEDAN LS</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>71759</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>GM</td>\n",
       "      <td>6418.0</td>\n",
       "      <td>7325.0</td>\n",
       "      <td>7431.0</td>\n",
       "      <td>8411.0</td>\n",
       "      <td>6785.0</td>\n",
       "      <td>8132.0</td>\n",
       "      <td>10151.0</td>\n",
       "      <td>11652.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18881</td>\n",
       "      <td>30212</td>\n",
       "      <td>GA</td>\n",
       "      <td>6200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65683</th>\n",
       "      <td>0</td>\n",
       "      <td>12/2/2009</td>\n",
       "      <td>ADESA</td>\n",
       "      <td>2005</td>\n",
       "      <td>4</td>\n",
       "      <td>JEEP</td>\n",
       "      <td>GRAND CHEROKEE 2WD V</td>\n",
       "      <td>Lar</td>\n",
       "      <td>4D WAGON LAREDO</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>88500</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>MEDIUM SUV</td>\n",
       "      <td>CHRYSLER</td>\n",
       "      <td>8545.0</td>\n",
       "      <td>9959.0</td>\n",
       "      <td>9729.0</td>\n",
       "      <td>11256.0</td>\n",
       "      <td>8375.0</td>\n",
       "      <td>9802.0</td>\n",
       "      <td>11831.0</td>\n",
       "      <td>14402.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18111</td>\n",
       "      <td>30212</td>\n",
       "      <td>GA</td>\n",
       "      <td>8200.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1893</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       IsBadBuy  PurchDate Auction  VehYear  VehicleAge       Make  \\\n",
       "65679         0  12/2/2009   ADESA     2004           5       FORD   \n",
       "65680         0  12/2/2009   ADESA     2006           3        KIA   \n",
       "65681         1  12/2/2009   ADESA     2001           8    MERCURY   \n",
       "65682         0  12/2/2009   ADESA     2007           2  CHEVROLET   \n",
       "65683         0  12/2/2009   ADESA     2005           4       JEEP   \n",
       "\n",
       "                      Model Trim             SubModel   Color Transmission  \\\n",
       "65679       EXPLORER 2WD V6  XLS  4D SUV 4.0L FFV XLS  SILVER         AUTO   \n",
       "65680           SORENTO 2WD   EX  4D SPORT UTILITY EX    GOLD         AUTO   \n",
       "65681                 SABLE   GS          4D SEDAN GS   BLACK         AUTO   \n",
       "65682             MALIBU 4C   LS          4D SEDAN LS  SILVER         AUTO   \n",
       "65683  GRAND CHEROKEE 2WD V  Lar      4D WAGON LAREDO  SILVER         AUTO   \n",
       "\n",
       "       WheelTypeID WheelType  VehOdo  Nationality        Size  \\\n",
       "65679          1.0     Alloy   82563     AMERICAN  MEDIUM SUV   \n",
       "65680          1.0     Alloy   65399  OTHER ASIAN  MEDIUM SUV   \n",
       "65681          1.0     Alloy   45234     AMERICAN      MEDIUM   \n",
       "65682          NaN       NaN   71759     AMERICAN      MEDIUM   \n",
       "65683          1.0     Alloy   88500     AMERICAN  MEDIUM SUV   \n",
       "\n",
       "      TopThreeAmericanName  MMRAcquisitionAuctionAveragePrice  \\\n",
       "65679                 FORD                             4668.0   \n",
       "65680                OTHER                             7843.0   \n",
       "65681                 FORD                             1996.0   \n",
       "65682                   GM                             6418.0   \n",
       "65683             CHRYSLER                             8545.0   \n",
       "\n",
       "       MMRAcquisitionAuctionCleanPrice  MMRAcquisitionRetailAveragePrice  \\\n",
       "65679                           5714.0                            5541.0   \n",
       "65680                           9171.0                            8970.0   \n",
       "65681                           2993.0                            2656.0   \n",
       "65682                           7325.0                            7431.0   \n",
       "65683                           9959.0                            9729.0   \n",
       "\n",
       "       MMRAcquisitonRetailCleanPrice  MMRCurrentAuctionAveragePrice  \\\n",
       "65679                         6671.0                         6148.0   \n",
       "65680                        10405.0                         7652.0   \n",
       "65681                         3732.0                         2190.0   \n",
       "65682                         8411.0                         6785.0   \n",
       "65683                        11256.0                         8375.0   \n",
       "\n",
       "       MMRCurrentAuctionCleanPrice  MMRCurrentRetailAveragePrice  \\\n",
       "65679                       7521.0                        9659.0   \n",
       "65680                       9310.0                       12148.0   \n",
       "65681                       3055.0                        4836.0   \n",
       "65682                       8132.0                       10151.0   \n",
       "65683                       9802.0                       11831.0   \n",
       "\n",
       "       MMRCurrentRetailCleanPrice PRIMEUNIT AUCGUART  BYRNO  VNZIP1 VNST  \\\n",
       "65679                     10944.0       NaN      NaN  18881   30212   GA   \n",
       "65680                     14204.0       NaN      NaN  18111   30212   GA   \n",
       "65681                      5937.0       NaN      NaN  18111   30212   GA   \n",
       "65682                     11652.0       NaN      NaN  18881   30212   GA   \n",
       "65683                     14402.0       NaN      NaN  18111   30212   GA   \n",
       "\n",
       "       VehBCost  IsOnlineSale  WarrantyCost  \n",
       "65679    7000.0             0          1243  \n",
       "65680    7900.0             0          1508  \n",
       "65681    4200.0             0           993  \n",
       "65682    6200.0             0          1038  \n",
       "65683    8200.0             0          1893  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with pd.option_context('display.max_columns', 200):\n",
    "    display(df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Summarize the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Before selecting variables to use for our model, we will stop and try to understand at a high level what our variables are. The below table provides a summary of all of our variables.\n",
    "\n",
    "First, you can see that there really are two types of variables, continuous and categorical. Continuous features are those features that change continuously, like price or age of vehicle. These can take any value (even a negative number sometimes). Categorical features by contrast represent categories of items. An example of a categorical feature is the make of a car.\n",
    "\n",
    "You generally treat these two different kind of variables very different when building a model. Specifically, for categorical features, you can't give them directly to a model because the model expects numbers. Instead, you create a new feature that is a \"dummy variable\" for each realization of a category. For example, if we are thinking about the make of a car, one make might be Toyota. So, we would create a new variable called \"Make_Toyota\" and the value would be 1 for any car that was a Toyota and 0 for any car that was not a Toyota. This means that you really need to pay careful attention to which categorical variable you add into the model. Since there are 1041 different unique values for the Model of a car, if you add in this variable, you will be adding 1041 variables to your model. This can add a lot of columns to your data set very quickly.\n",
    "\n",
    "Look through the summary below to begin identify which variables might make sense for your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Missing Values</th>\n",
       "      <th>Unique Values</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IsBadBuy</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.122891</td>\n",
       "      <td>0.328315</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PurchDate</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>517</td>\n",
       "      <td>65684.0</td>\n",
       "      <td>517</td>\n",
       "      <td>11/23/2010</td>\n",
       "      <td>349</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Auction</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>65684.0</td>\n",
       "      <td>3</td>\n",
       "      <td>MANHEIM</td>\n",
       "      <td>36940</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehYear</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2005.344041</td>\n",
       "      <td>1.729519</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2004.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>2007.0</td>\n",
       "      <td>2010.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehicleAge</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4.175842</td>\n",
       "      <td>1.710202</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Make</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>65684.0</td>\n",
       "      <td>32</td>\n",
       "      <td>CHEVROLET</td>\n",
       "      <td>15504</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>1041</td>\n",
       "      <td>65684.0</td>\n",
       "      <td>1041</td>\n",
       "      <td>PT CRUISER</td>\n",
       "      <td>2094</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Trim</th>\n",
       "      <td>object</td>\n",
       "      <td>2143</td>\n",
       "      <td>134</td>\n",
       "      <td>63541.0</td>\n",
       "      <td>134</td>\n",
       "      <td>Bas</td>\n",
       "      <td>12615</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SubModel</th>\n",
       "      <td>object</td>\n",
       "      <td>8</td>\n",
       "      <td>846</td>\n",
       "      <td>65676.0</td>\n",
       "      <td>846</td>\n",
       "      <td>4D SEDAN</td>\n",
       "      <td>13737</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Color</th>\n",
       "      <td>object</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>65676.0</td>\n",
       "      <td>16</td>\n",
       "      <td>SILVER</td>\n",
       "      <td>13397</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Transmission</th>\n",
       "      <td>object</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>65675.0</td>\n",
       "      <td>3</td>\n",
       "      <td>AUTO</td>\n",
       "      <td>63339</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WheelTypeID</th>\n",
       "      <td>float64</td>\n",
       "      <td>2845</td>\n",
       "      <td>4</td>\n",
       "      <td>62839.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.494725</td>\n",
       "      <td>0.52114</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WheelType</th>\n",
       "      <td>object</td>\n",
       "      <td>2849</td>\n",
       "      <td>3</td>\n",
       "      <td>62835.0</td>\n",
       "      <td>3</td>\n",
       "      <td>Alloy</td>\n",
       "      <td>32418</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehOdo</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>37858</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>71483.34328</td>\n",
       "      <td>14591.106035</td>\n",
       "      <td>4825.0</td>\n",
       "      <td>61831.75</td>\n",
       "      <td>73364.5</td>\n",
       "      <td>82417.25</td>\n",
       "      <td>115717.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nationality</th>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65681.0</td>\n",
       "      <td>4</td>\n",
       "      <td>AMERICAN</td>\n",
       "      <td>54950</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size</th>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>65681.0</td>\n",
       "      <td>12</td>\n",
       "      <td>MEDIUM</td>\n",
       "      <td>27683</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopThreeAmericanName</th>\n",
       "      <td>object</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>65681.0</td>\n",
       "      <td>4</td>\n",
       "      <td>GM</td>\n",
       "      <td>22789</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRAcquisitionAuctionAveragePrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>17</td>\n",
       "      <td>10137</td>\n",
       "      <td>65667.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6125.349841</td>\n",
       "      <td>2460.539469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4273.0</td>\n",
       "      <td>6093.0</td>\n",
       "      <td>7761.0</td>\n",
       "      <td>35722.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRAcquisitionAuctionCleanPrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>17</td>\n",
       "      <td>11132</td>\n",
       "      <td>65667.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7370.385475</td>\n",
       "      <td>2721.753111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5407.5</td>\n",
       "      <td>7301.0</td>\n",
       "      <td>9016.0</td>\n",
       "      <td>36859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRAcquisitionRetailAveragePrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>17</td>\n",
       "      <td>12463</td>\n",
       "      <td>65667.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8494.345638</td>\n",
       "      <td>3155.976296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6275.0</td>\n",
       "      <td>8446.0</td>\n",
       "      <td>10648.0</td>\n",
       "      <td>39080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRAcquisitonRetailCleanPrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>17</td>\n",
       "      <td>13139</td>\n",
       "      <td>65667.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>9848.729819</td>\n",
       "      <td>3386.141054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7495.5</td>\n",
       "      <td>9793.0</td>\n",
       "      <td>12087.0</td>\n",
       "      <td>41482.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRCurrentAuctionAveragePrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>287</td>\n",
       "      <td>10085</td>\n",
       "      <td>65397.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6129.900622</td>\n",
       "      <td>2431.61925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4278.0</td>\n",
       "      <td>6062.0</td>\n",
       "      <td>7734.0</td>\n",
       "      <td>35722.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRCurrentAuctionCleanPrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>287</td>\n",
       "      <td>11005</td>\n",
       "      <td>65397.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7389.135511</td>\n",
       "      <td>2683.606507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5420.0</td>\n",
       "      <td>7315.0</td>\n",
       "      <td>9014.0</td>\n",
       "      <td>36859.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRCurrentRetailAveragePrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>287</td>\n",
       "      <td>12203</td>\n",
       "      <td>65397.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8774.571081</td>\n",
       "      <td>3087.737342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6540.0</td>\n",
       "      <td>8733.0</td>\n",
       "      <td>10910.0</td>\n",
       "      <td>39080.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MMRCurrentRetailCleanPrice</th>\n",
       "      <td>float64</td>\n",
       "      <td>287</td>\n",
       "      <td>12860</td>\n",
       "      <td>65397.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>10145.086808</td>\n",
       "      <td>3307.200028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7790.0</td>\n",
       "      <td>10103.0</td>\n",
       "      <td>12309.0</td>\n",
       "      <td>41062.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PRIMEUNIT</th>\n",
       "      <td>object</td>\n",
       "      <td>62584</td>\n",
       "      <td>2</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>3044</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUCGUART</th>\n",
       "      <td>object</td>\n",
       "      <td>62584</td>\n",
       "      <td>2</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>2</td>\n",
       "      <td>GREEN</td>\n",
       "      <td>3030</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BYRNO</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>26371.316363</td>\n",
       "      <td>25739.146373</td>\n",
       "      <td>835.0</td>\n",
       "      <td>17212.0</td>\n",
       "      <td>19662.0</td>\n",
       "      <td>22808.0</td>\n",
       "      <td>99761.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VNZIP1</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>58019.770903</td>\n",
       "      <td>26157.83753</td>\n",
       "      <td>2764.0</td>\n",
       "      <td>32124.0</td>\n",
       "      <td>73108.0</td>\n",
       "      <td>80022.0</td>\n",
       "      <td>99224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VNST</th>\n",
       "      <td>object</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>65684.0</td>\n",
       "      <td>37</td>\n",
       "      <td>TX</td>\n",
       "      <td>12273</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VehBCost</th>\n",
       "      <td>float64</td>\n",
       "      <td>0</td>\n",
       "      <td>2040</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6728.775914</td>\n",
       "      <td>1768.271289</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5430.0</td>\n",
       "      <td>6700.0</td>\n",
       "      <td>7900.0</td>\n",
       "      <td>45469.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsOnlineSale</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.025242</td>\n",
       "      <td>0.156861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WarrantyCost</th>\n",
       "      <td>int64</td>\n",
       "      <td>0</td>\n",
       "      <td>280</td>\n",
       "      <td>65684.0</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1275.835698</td>\n",
       "      <td>597.383625</td>\n",
       "      <td>462.0</td>\n",
       "      <td>837.0</td>\n",
       "      <td>1155.0</td>\n",
       "      <td>1623.0</td>\n",
       "      <td>7498.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  Data Type  Missing Values  Unique Values  \\\n",
       "IsBadBuy                              int64               0              2   \n",
       "PurchDate                            object               0            517   \n",
       "Auction                              object               0              3   \n",
       "VehYear                               int64               0             10   \n",
       "VehicleAge                            int64               0             10   \n",
       "Make                                 object               0             32   \n",
       "Model                                object               0           1041   \n",
       "Trim                                 object            2143            134   \n",
       "SubModel                             object               8            846   \n",
       "Color                                object               8             16   \n",
       "Transmission                         object               9              3   \n",
       "WheelTypeID                         float64            2845              4   \n",
       "WheelType                            object            2849              3   \n",
       "VehOdo                                int64               0          37858   \n",
       "Nationality                          object               3              4   \n",
       "Size                                 object               3             12   \n",
       "TopThreeAmericanName                 object               3              4   \n",
       "MMRAcquisitionAuctionAveragePrice   float64              17          10137   \n",
       "MMRAcquisitionAuctionCleanPrice     float64              17          11132   \n",
       "MMRAcquisitionRetailAveragePrice    float64              17          12463   \n",
       "MMRAcquisitonRetailCleanPrice       float64              17          13139   \n",
       "MMRCurrentAuctionAveragePrice       float64             287          10085   \n",
       "MMRCurrentAuctionCleanPrice         float64             287          11005   \n",
       "MMRCurrentRetailAveragePrice        float64             287          12203   \n",
       "MMRCurrentRetailCleanPrice          float64             287          12860   \n",
       "PRIMEUNIT                            object           62584              2   \n",
       "AUCGUART                             object           62584              2   \n",
       "BYRNO                                 int64               0             73   \n",
       "VNZIP1                                int64               0            151   \n",
       "VNST                                 object               0             37   \n",
       "VehBCost                            float64               0           2040   \n",
       "IsOnlineSale                          int64               0              2   \n",
       "WarrantyCost                          int64               0            280   \n",
       "\n",
       "                                     count unique         top   freq  \\\n",
       "IsBadBuy                           65684.0                             \n",
       "PurchDate                          65684.0    517  11/23/2010    349   \n",
       "Auction                            65684.0      3     MANHEIM  36940   \n",
       "VehYear                            65684.0                             \n",
       "VehicleAge                         65684.0                             \n",
       "Make                               65684.0     32   CHEVROLET  15504   \n",
       "Model                              65684.0   1041  PT CRUISER   2094   \n",
       "Trim                               63541.0    134         Bas  12615   \n",
       "SubModel                           65676.0    846    4D SEDAN  13737   \n",
       "Color                              65676.0     16      SILVER  13397   \n",
       "Transmission                       65675.0      3        AUTO  63339   \n",
       "WheelTypeID                        62839.0                             \n",
       "WheelType                          62835.0      3       Alloy  32418   \n",
       "VehOdo                             65684.0                             \n",
       "Nationality                        65681.0      4    AMERICAN  54950   \n",
       "Size                               65681.0     12      MEDIUM  27683   \n",
       "TopThreeAmericanName               65681.0      4          GM  22789   \n",
       "MMRAcquisitionAuctionAveragePrice  65667.0                             \n",
       "MMRAcquisitionAuctionCleanPrice    65667.0                             \n",
       "MMRAcquisitionRetailAveragePrice   65667.0                             \n",
       "MMRAcquisitonRetailCleanPrice      65667.0                             \n",
       "MMRCurrentAuctionAveragePrice      65397.0                             \n",
       "MMRCurrentAuctionCleanPrice        65397.0                             \n",
       "MMRCurrentRetailAveragePrice       65397.0                             \n",
       "MMRCurrentRetailCleanPrice         65397.0                             \n",
       "PRIMEUNIT                           3100.0      2          NO   3044   \n",
       "AUCGUART                            3100.0      2       GREEN   3030   \n",
       "BYRNO                              65684.0                             \n",
       "VNZIP1                             65684.0                             \n",
       "VNST                               65684.0     37          TX  12273   \n",
       "VehBCost                           65684.0                             \n",
       "IsOnlineSale                       65684.0                             \n",
       "WarrantyCost                       65684.0                             \n",
       "\n",
       "                                           mean           std     min  \\\n",
       "IsBadBuy                               0.122891      0.328315     0.0   \n",
       "PurchDate                                                               \n",
       "Auction                                                                 \n",
       "VehYear                             2005.344041      1.729519  2001.0   \n",
       "VehicleAge                             4.175842      1.710202     0.0   \n",
       "Make                                                                    \n",
       "Model                                                                   \n",
       "Trim                                                                    \n",
       "SubModel                                                                \n",
       "Color                                                                   \n",
       "Transmission                                                            \n",
       "WheelTypeID                            1.494725       0.52114     0.0   \n",
       "WheelType                                                               \n",
       "VehOdo                              71483.34328  14591.106035  4825.0   \n",
       "Nationality                                                             \n",
       "Size                                                                    \n",
       "TopThreeAmericanName                                                    \n",
       "MMRAcquisitionAuctionAveragePrice   6125.349841   2460.539469     0.0   \n",
       "MMRAcquisitionAuctionCleanPrice     7370.385475   2721.753111     0.0   \n",
       "MMRAcquisitionRetailAveragePrice    8494.345638   3155.976296     0.0   \n",
       "MMRAcquisitonRetailCleanPrice       9848.729819   3386.141054     0.0   \n",
       "MMRCurrentAuctionAveragePrice       6129.900622    2431.61925     0.0   \n",
       "MMRCurrentAuctionCleanPrice         7389.135511   2683.606507     0.0   \n",
       "MMRCurrentRetailAveragePrice        8774.571081   3087.737342     0.0   \n",
       "MMRCurrentRetailCleanPrice         10145.086808   3307.200028     0.0   \n",
       "PRIMEUNIT                                                               \n",
       "AUCGUART                                                                \n",
       "BYRNO                              26371.316363  25739.146373   835.0   \n",
       "VNZIP1                             58019.770903   26157.83753  2764.0   \n",
       "VNST                                                                    \n",
       "VehBCost                            6728.775914   1768.271289     1.0   \n",
       "IsOnlineSale                           0.025242      0.156861     0.0   \n",
       "WarrantyCost                        1275.835698    597.383625   462.0   \n",
       "\n",
       "                                        25%      50%       75%       max  \n",
       "IsBadBuy                                0.0      0.0       0.0       1.0  \n",
       "PurchDate                                                                 \n",
       "Auction                                                                   \n",
       "VehYear                              2004.0   2005.0    2007.0    2010.0  \n",
       "VehicleAge                              3.0      4.0       5.0       9.0  \n",
       "Make                                                                      \n",
       "Model                                                                     \n",
       "Trim                                                                      \n",
       "SubModel                                                                  \n",
       "Color                                                                     \n",
       "Transmission                                                              \n",
       "WheelTypeID                             1.0      1.0       2.0       3.0  \n",
       "WheelType                                                                 \n",
       "VehOdo                             61831.75  73364.5  82417.25  115717.0  \n",
       "Nationality                                                               \n",
       "Size                                                                      \n",
       "TopThreeAmericanName                                                      \n",
       "MMRAcquisitionAuctionAveragePrice    4273.0   6093.0    7761.0   35722.0  \n",
       "MMRAcquisitionAuctionCleanPrice      5407.5   7301.0    9016.0   36859.0  \n",
       "MMRAcquisitionRetailAveragePrice     6275.0   8446.0   10648.0   39080.0  \n",
       "MMRAcquisitonRetailCleanPrice        7495.5   9793.0   12087.0   41482.0  \n",
       "MMRCurrentAuctionAveragePrice        4278.0   6062.0    7734.0   35722.0  \n",
       "MMRCurrentAuctionCleanPrice          5420.0   7315.0    9014.0   36859.0  \n",
       "MMRCurrentRetailAveragePrice         6540.0   8733.0   10910.0   39080.0  \n",
       "MMRCurrentRetailCleanPrice           7790.0  10103.0   12309.0   41062.0  \n",
       "PRIMEUNIT                                                                 \n",
       "AUCGUART                                                                  \n",
       "BYRNO                               17212.0  19662.0   22808.0   99761.0  \n",
       "VNZIP1                              32124.0  73108.0   80022.0   99224.0  \n",
       "VNST                                                                      \n",
       "VehBCost                             5430.0   6700.0    7900.0   45469.0  \n",
       "IsOnlineSale                            0.0      0.0       0.0       1.0  \n",
       "WarrantyCost                          837.0   1155.0    1623.0    7498.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_dataframe(df):\n",
    "    missing_values = pd.concat([pd.DataFrame(df.columns, columns=['Variable Name']), \n",
    "                      pd.DataFrame(df.dtypes.values.reshape([-1,1]), columns=['Data Type']),\n",
    "                      pd.DataFrame(df.isnull().sum().values, columns=['Missing Values']), \n",
    "                      pd.DataFrame([df[name].nunique() for name in df.columns], columns=['Unique Values'])], \n",
    "                     axis=1).set_index('Variable Name')\n",
    "    return pd.concat([missing_values, df.describe(include='all').transpose()], axis=1).fillna(\"\")\n",
    "\n",
    "summarize_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Engineer features and impute missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A big part of any data science project is getting the data ready to be analyzed by a model. Models often have very strict expectations about the format of data that they will use, and if that format is not met, the model will give an error. Additionally, often the data we have is not exactly in the form that we think will make modeling easiest, so often we *engineer* new features, i.e. create a new feature using existing features. This can often lead to much better performance, but knowing what features to engineer can sometimes be a challenge.\n",
    "\n",
    "Additionally, anything done to the *training* data set will also have to be done to the *testing* and *validation* data sets, so if you change the data to build your model, you need to also change the data before you use your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Convert PurchDate (the date in which Carvana purchased the car) column from an object (i.e., string) to a formal datetime object in Python. This will allow us to use it more easily as a date in our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if 'PurchDate' in df:\n",
    "    df['PurchDate'] = pd.to_datetime(df['PurchDate'], format='%m/%d/%Y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Instead of using the variable directly, we will engineer two new features based on the purchase date: month and year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "if 'PurchDate' in df:\n",
    "    df['Month'] = df['PurchDate'].dt.month\n",
    "    df['Year'] = df['PurchDate'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now we no longer need the PurchDate column and we will drop it from the data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_263/353006286.py:2: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df = df.drop('PurchDate', 1)\n"
     ]
    }
   ],
   "source": [
    "if 'PurchDate' in df:\n",
    "    df = df.drop('PurchDate', 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Finally, we will go ahead and explicitly categorize which variables are continuous and which are categorical. This is not always obvious becuase some variables (WheelTypeID specifically) looked like a continuous variable in the summary above, but is actually a categorical variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "continuous_features = ['VehOdo', 'MMRAcquisitionAuctionAveragePrice', 'MMRAcquisitionAuctionCleanPrice',\n",
    "                       'MMRAcquisitionRetailAveragePrice', 'MMRAcquisitonRetailCleanPrice',\n",
    "                       'MMRCurrentAuctionAveragePrice', 'MMRCurrentAuctionCleanPrice',\n",
    "                       'MMRCurrentRetailAveragePrice', 'MMRCurrentRetailCleanPrice', 'VehBCost', 'WarrantyCost', 'VehYear', 'VehicleAge']\n",
    "categorical_features = ['Auction', 'Make', 'Model', 'Trim', 'SubModel', 'Color', \n",
    "                        'Transmission', 'WheelTypeID', 'WheelType', 'Nationality', \n",
    "                        'Size', 'TopThreeAmericanName', 'PRIMEUNIT', 'AUCGUART', \n",
    "                        'BYRNO', 'VNZIP1', 'VNST', 'IsOnlineSale', 'Month', 'Year']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Models also expect that all of variables in all of the rows have numbers in them. They generally can't handle missing data. However, our data has lots of missing values (refer to the table where we summarized the data). We could throw out all rows with missing values, but that would mean throwing out 62,584 rows (see PRIMEUNIT). We could also drop any columns with missing values, but that would be most columns. Instead, we *impute* the missing values, where we fill in the values with something reasonable. For continuous features, we fill in the value with the mean value of everything else in the column. With categorical features, we add a new category called \"MISSING\" that gets its own dummy variable.\n",
    "\n",
    "However, if a variable is primarily missing (e.g. PRIMEUNIT), then the new imputed values are not likely to provide much information. It is probably not a good idea to include those variables in your model unless you have a compelling reason to do so.\n",
    "\n",
    "The following code creates a *transformer* that transforms our data using the above strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def convert_to_str(df):\n",
    "    return df[:].astype(str)\n",
    "\n",
    "def convert_to_object(df):\n",
    "    return df[:].astype(object)\n",
    "\n",
    "numeric_transformer = Pipeline([('fill_NaN', SimpleImputer(missing_values=np.nan, strategy='mean'))])\n",
    "categorical_transformer = Pipeline([('convert_objects', FunctionTransformer(convert_to_object, validate=False)),\n",
    "                                    ('fill_Missing', SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='MISSING')), \n",
    "                                    ('convert_floats', FunctionTransformer(convert_to_str, validate=False)),\n",
    "                                    ('dummy_transform', OneHotEncoder(handle_unknown='ignore', sparse=False))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Visualizing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Before we decide what variables to include in the model, it is useful to spend a little bit of time visualizing the data set to try to decide what to include when modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "550e304fa6ae43848b1e09dd872aa9a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Variable on the horizontal axis:', index=17, layout=Layout(width='"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_df = df.copy()\n",
    "plot_df[categorical_features] = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value='MISSING').fit_transform(df[categorical_features])\n",
    "\n",
    "def plot_variables(v1, v2):\n",
    "    if v1 in categorical_features + ['IsBadBuy'] and v2 in continuous_features + ['IsBadBuy']:\n",
    "        print(\"You have selected \" + str(v1) + \" (a categorical feature) for the horizontal axis and \" + str(v2) + \" for the vertical axis.\")\n",
    "        print(\"The first plot plots the average value of \" + str(v2) + \" for each category in \" + str(v1) + \".\")\n",
    "        g = sns.catplot(x=v1, y=v2,\n",
    "                        saturation=.5, data=plot_df,\n",
    "                        kind=\"bar\", ci=None, aspect=5)\n",
    "        g.set_xticklabels(rotation=45)\n",
    "        print(\"The second plot plots the count of \" + str(v1) + \" in each category.\")\n",
    "        g = sns.catplot(x=v1, \n",
    "                        saturation=.5, data=plot_df,\n",
    "                        kind=\"count\", ci=None, aspect=5)\n",
    "        g.set_xticklabels(rotation=45)\n",
    "    elif v1 in continuous_features and v2 in categorical_features + ['IsBadBuy']:\n",
    "        print(\"You have selected \" + str(v1) + \" (a continuous feature) for the horizontal axis and \" + str(v2) + \" (a categorical feature) for the vertical axis.\")\n",
    "        print(\"This plots the average value of \" + str(v1) + \" for each category in \" + str(v2) + \"\\nand it shows the distribution of \" + str(v1) + \" within each category represented by the width of the plot at each point.\")\n",
    "        g = sns.catplot(x=v1, y=v2,\n",
    "                        saturation=.5, data=plot_df, orient='h', \n",
    "                        kind=\"violin\", ci=None, aspect=5, scale='count')\n",
    "        g.set_xticklabels(rotation=45)\n",
    "    elif v1 in categorical_features + ['IsBadBuy'] and v2 in categorical_features:\n",
    "        print(\"You have selected \" + str(v1) + \" (a categorical feature) for the horizontal axis and \" + str(v2) + \" (a categorical feature) for the vertical axis.\")\n",
    "        print(\"This plots a heatmap showing the relationship betweeen the two categories.\")\n",
    "        print(\"A bright color means those two categories are seen together more often.\")\n",
    "        fig, ax = plt.subplots(figsize=(10,10))\n",
    "        temp = pd.crosstab(plot_df[v2], plot_df[v1])\n",
    "        sns.heatmap(temp, cbar=True, ax=ax)\n",
    "        ax.set_xticklabels(ax.get_xticklabels(), rotation=45)\n",
    "        ax.set_yticklabels(ax.get_yticklabels(), rotation=45)\n",
    "    elif v1 in continuous_features and v2 in continuous_features:\n",
    "        print(\"You have selected \" + str(v1) + \" (a continuous feature) for the horizontal axis and \" + str(v2) + \" (a continuous feature) for the vertical axis.\")\n",
    "        print(\"This plots a scatterplot between the two variales, and it shows histograms of the variables individually on the outer axis.\")\n",
    "        sns.jointplot(x=v1, y=v2, data=plot_df)\n",
    "\n",
    "\n",
    "\n",
    "plot_relationships = interactive(plot_variables, \n",
    "#                            {'manual' : True, 'manual_name' : 'Display plot'}, \n",
    "                           v1 = widgets.Dropdown(value='VNST',\n",
    "                                                options=['IsBadBuy'] + categorical_features + continuous_features,\n",
    "                                                description=\"Variable on the horizontal axis:\", \n",
    "                                                style={'description_width': 'initial'},\n",
    "                                                layout=Layout(width='500px'),\n",
    "                                                disabled=False), \n",
    "                           v2 = widgets.Dropdown(value='IsBadBuy',\n",
    "                                                options=['IsBadBuy'] + categorical_features + continuous_features,\n",
    "                                                description=\"Variable on the vertical axis:\", \n",
    "                                                style={'description_width': 'initial'},\n",
    "                                                layout=Layout(width='500px'),\n",
    "                                                disabled=False)\n",
    "                                )\n",
    "display(plot_relationships)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Splitting into training and testing and selecting features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "One of the most important concepts for data science is the idea of \"out of sample\" testing. I.e., you have to test your model on data that it was not trained on. The models used by data scientists are incredibly powerful, and if you are not careful, the model can \"memorize\" the data set instead of uncovering true, robust patterns. This leads to something that data scientists call **overfitting**. The only way to test for overfitting is to split your data into two data sets: a *training set* which you use to train your model and a *testing set* which you only use to evaluate your model.\n",
    "\n",
    "However, this naturally means that you have less data to train your model on, and generally speaking, models do better the more data they have to train on. However, the more testing data you have, the more confident you can be in the performance of your model. This sets up a natural tension between how much data you hold out for testing versus training. The below slider will let you choose the percentage of data to hold out for testing. Again, the fundamental tradeoff is the more data you hold out testing, the worse your best model is likely to be, but the more data you hold out for testing, the more likely you are to identify the best of (the slightly worse) models. How will you choose?\n",
    "\n",
    "Therefore, when you are testing your model, your final score will be much closer to the score you have on your testing set. However, the score will not be the same as that of your testing set because I have held out a third set of data that you do not have that will be used for the final validation. You will not know your true score until we run the competition in class, but it should be similar to your testing set score unless you use a really small test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Additionally, we have to choose what features our model will actually use. While you can choose all of the features, you may find that it \"overfits.\" We have roughly 70,000 rows of data and there are 2,410 columns after adding all of the dummies for the categorical variables. By selecting fewer variables, our model may be more robust to new data. Moreover, the more variables you pick, the longer it will take to train the models, and the less time you will have to tune the models. Do you go with more variables and less tuning time or less variables and more tuning time?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "The next piece of code will allow you to choose the size of your testing set and the variables on which to build your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac25a2223b74b0c8c342b6cff446001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntSlider(value=20, description='Proportion of data for testing:', layout=Layout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_data_set(df, percent_test, **kwargs):\n",
    "    print(\"You will hold out \" + str(percent_test) + \"% of the data for the test set.\\nYou will have \" + str(math.floor((1 - percent_test/100)*len(df))) \n",
    "          + \" rows in your training set and \" + str(math.ceil((percent_test/100)*len(df))) + \" in your test set.\")\n",
    "    features_selected = {key for key, value in kwargs.items() if value}\n",
    "    cont_features_selected = list(features_selected.intersection(continuous_features))\n",
    "    cat_features_selected = list(features_selected.intersection(categorical_features))\n",
    "    print(\"\\nThe continuous features you have selected are \" + str(cont_features_selected))\n",
    "    print(\"The categorical features you have selected are \" + str(cat_features_selected) + '\\n')\n",
    "    \n",
    "    X=df.drop('IsBadBuy',1)\n",
    "    if not cat_features_selected and not cont_features_selected:\n",
    "        print(\"You have to choose something! Choose some variables and create the data set.\")\n",
    "        raise Exception(\"No variables chosen!\")\n",
    "        return\n",
    "    elif not cat_features_selected:\n",
    "        preprocessor = ColumnTransformer(transformers = [('num', numeric_transformer, cont_features_selected)])\n",
    "        preprocessor.fit(X)\n",
    "        feature_names = cont_features_selected\n",
    "        X = pd.DataFrame(preprocessor.transform(X), columns=feature_names)\n",
    "    else:\n",
    "        preprocessor = ColumnTransformer(transformers = [('num', numeric_transformer, cont_features_selected),\n",
    "                                                         ('cat', categorical_transformer, cat_features_selected)])\n",
    "        preprocessor.fit(X)\n",
    "        feature_names=cont_features_selected + list(preprocessor.transformers_[1][1]['dummy_transform'].get_feature_names(cat_features_selected))\n",
    "        X = pd.DataFrame(preprocessor.transform(X), \n",
    "                         columns=feature_names)\n",
    "    \n",
    "    \n",
    "    y = df['IsBadBuy']\n",
    "    print(\"The first ten rows of your data set now looks like:\")\n",
    "    display(X.head(10))\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=percent_test/100, random_state=201)\n",
    "    print(\"\\nThe number of columns in your data set is: \" + str(len(X.columns)))\n",
    "    print(\"\\nThe number of rows in your training set is: \" + str(len(X_train)) + \"\\nThe number of rows in your testing set is: \" + str(len(X_test)))\n",
    "    \n",
    "    return feature_names, preprocessor, X_train, X_test, y_train, y_test, cont_features_selected, cat_features_selected\n",
    "\n",
    "\n",
    "feature_selection = interactive(create_data_set, \n",
    "                               {'manual' : True, 'manual_name' : 'Create Data Set'},\n",
    "                                df=fixed(df[:]),\n",
    "                                percent_test= widgets.IntSlider(min=1, \n",
    "                                                                 max=99, \n",
    "                                                                 step=1, \n",
    "                                                                 value=20,\n",
    "                                                                 layout=Layout(width='500px'), \n",
    "                                                                 style={'description_width': 'initial'}, \n",
    "                                                                 description=\"Proportion of data for testing:\"),\n",
    "                                **{str(col):widgets.Checkbox(value=False, description=str(col), style = {'description_width': 'initial'}) for col in df.columns if col != 'IsBadBuy'}\n",
    "                          )\n",
    "\n",
    "controls = VBox([HBox([feature_selection.children[0]], layout = Layout(display='flex', flex_flow='column', align_items='center')), \n",
    "                 HBox(feature_selection.children[1:-2], layout = Layout(flex_flow='row wrap')), \n",
    "                 HBox([feature_selection.children[-2]], layout = Layout(display='flex', flex_flow='column', align_items='center')), \n",
    "                 HBox([feature_selection.children[-1]], layout = Layout(max_width='800px', display='inline-flex'))])\n",
    "\n",
    "display(controls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Note that you must select **at least one** checkbox above before moving on and then pressing the \"Create Data Set\" button. If you do not select at least one checkbox and push the button, you will get an error in the following code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "How many columns did we end up with?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "That may not be equal to the number of checkboxes you selected. Why?\n",
    "\n",
    "How many rows are in your testing set? The training set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Set up the scoring metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As important as model building is the choice of the right model evaluation criteria is equally as important. The model that you choose will be dictated by the metric with which you measure it. That metric should reflect the intended use of the model.\n",
    "\n",
    "For the Carvana challenge, Kaggle uses scaled version of the normalized Gini index. The normalized Gini index is 2\\*AUC - 1, where AUC is the area under the receiver operating curve (a plot of false positive rate vs. true positive rate for all possible thresholds). AUC is a very popular evaluation metric in machine learning challenges. A brief explanation of AUC can be found at https://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it, but for the purposes of this challenge, the AUC can be thought of as a metric that balances the penalty for false positives (i.e. saying a car IsBadBuy when it isn't) with false negatives (i.e. saying a car IsGoodBuy when it isn't).\n",
    "\n",
    "The metric is fairly complicated, but the only really important information you need to know is that a **higher score is better**. The Kaggle competition was won with a score of .26, so that is an upper bound on what you will be able to achieve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def Kaggle_Gini_Index(predictions, realizations):\n",
    "    this_score = 0.43639 * (2 * roc_auc_score(realizations, predictions) - 1)\n",
    "    return this_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Additionally, any model should be measured against a benchmark. Often times, you will use an existing model to benchmark your new model. In this case since we do not have an existing model, we will use the *naive* model. This model just guesses that the probability of any particular car being a bad buy is equal to the proportion of bad buy cars in the data set. Why is this a reasonable model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Gini index for the naive model is 0.0\n"
     ]
    }
   ],
   "source": [
    "y_train = df['IsBadBuy']\n",
    "\n",
    "naive = np.repeat(np.mean(y_train), len(y_train))\n",
    "print(\"The Gini index for the naive model is \" + str(Kaggle_Gini_Index(naive, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A higher Gini index is better. The naive model has a Gini index of 0, so any model that is above 0 is at least better than the naive model. That's a benchmark to beat (probably not the one that will win you a prize)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Regularization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A core concept in data science is *regularization*. The models used in data science are often very powerful, and if they are left unchecked they can memorize the data that they have seen. The problem with this is that any real data set has noise that is either a result of the data collection process or is just intrinsic to the system. If a model memorizes the data, then it ends up fitting the noise and not the true pattern. A common example is in the below image to the right. The true data generating process is the smooth line in the middle plot and some noise added, but if we overfit we can end up with a model that goes crazy trying to exactly match the pattern.\n",
    "\n",
    "<img src=\"images/underfitting-overfitting.png\" width=\"600\"/>\n",
    "\n",
    "The way to avoid overfitting is to *regularize* your model, i.e. set a parameter that restrains its ability to memorize the data set. Generally this either takes the form of a penalty for being \"too wavy\" or constrains the class of models.\n",
    "\n",
    "However if you constrain your class of models too much, you end up *underfitting*, as seen in the image on the left above. To figure out where exactly you've landed, you need to pay careful attention to the model performance on the testing set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Regularized Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A logistic regression is the cousin to the common linear regression that most of us are likely familiar with. The logistic regression instead of fitting a straight line, it fits a *sigmoid* function that relates the dependent variables to the probability that something is true, in this case whether or not a car IsBadBuy. The below image demonstrates this for a single dependent variable. Note that for larger values of *x*, there are more type 1 points, so the sigmoid goes up as x goes up.\n",
    "\n",
    "<img src=\"images/Logistic_Regression.png\" width=\"500\"/>\n",
    "\n",
    "The nice thing about a logistic regression is that it is very easy to interpret the model. If you look at the coefficients, the size of a coefficient is related to the strength of the models response to a variable. Specifically, the coefficient indicates the change in probability of something happening for one standard deviation increase in that variable. So, a positive cofficient means that it makes it more likely for a car to be IsBadBuy, and a negative coefficient makes it less likely, at least as that variable goes up.\n",
    "\n",
    "These models are easy to translate into clear business decisions. Find the variables that have large positive coefficients and do not buy cars that have high values of those variables. Instead buy cars that have high values of variables that have large negative coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "In the regularized logistic regression model, the paramater C is the main tuning parameter here. It regularizes the logistic regression for penalizing large values of coefficients. So, the model will only assign a large coefficient to a variable if it is really clear that a large coefficient is warranted. The larger the C, the less regularization, and the smaller a C, more regularization. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Fit a logistic regression below. If you have chosen a lot of variables, this could take up to a minute or two to run. Play around with C and look at the effect on the training and the testing set. Note that there are three more models after this one to evaluate, so budget training time accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ab5048ba5e74d73b6a2d0e0fcdf1583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedFloatText(value=1.0, description='Regularization Parameter (C) (between .00001 an"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_logit(C):\n",
    "    print(\"Training the model, this could take a little bit of time...\")\n",
    "    X_train = feature_selection.result[2]\n",
    "    X_test = feature_selection.result[3]\n",
    "    y_train = feature_selection.result[4]\n",
    "    y_test = feature_selection.result[5]\n",
    "    cont_features_selected = feature_selection.result[6]\n",
    "    cat_features_selected = feature_selection.result[7]\n",
    "    scaler=StandardScaler().fit(X_train)\n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    features_selected = feature_selection.result[0]\n",
    "    preprocessor = Pipeline([('common_preprocessor', feature_selection.result[1]), ('scaler', scaler)])\n",
    "    algorithm_starts = time.time()\n",
    "    rlr = LogisticRegression(penalty='l1', C=C, random_state=201, solver='liblinear')\n",
    "    rlr_train = rlr.fit(X_train, y_train)\n",
    "    training_time = time.time() - algorithm_starts\n",
    "    \n",
    "    rlr_train_prob = pd.DataFrame(rlr_train.predict_proba(X_train))[1]\n",
    "    rlr_test_prob = pd.DataFrame(rlr_train.predict_proba(X_test))[1]\n",
    "    \n",
    "    output_string = \"For the Logistic Regression, the continuous features chosen were: \" + str(cont_features_selected) + \\\n",
    "                    \"\\nThe categorical features chosen were: \" + str(cat_features_selected) + \\\n",
    "                    \"\\nThe C parameter chosen was: \" + str(C) + \"\\n\"\n",
    "    \n",
    "    print(\"Training the model took \" + \"{:.3f}\".format(training_time) + \" seconds\\n\" \n",
    "          + \"The regularization parameter (C) is \" + str(C) + \"\\n\"\n",
    "          + \"In the test set, the Gini index is \" + \"{:.5f}\".format(Kaggle_Gini_Index(rlr_test_prob, y_test)) \n",
    "          + \" and in the training set it is \" + \"{:.5f}\".format(Kaggle_Gini_Index(rlr_train_prob, y_train)))\n",
    "    feature_importances = pd.concat([pd.DataFrame(features_selected, columns=['Variable']), \n",
    "                                     pd.DataFrame(rlr_train.coef_[0], columns=['Importance'])], axis=1\n",
    "                                   )\n",
    "    feature_importances = feature_importances.reindex(feature_importances.Importance.abs().sort_values(ascending=False).index).head(10).reset_index(drop=True)\n",
    "    print(\"\\nWe can also look at the ten most important features according to the model \\n(measured by the absolute size of the coefficient in the logistic regression):\")\n",
    "    display(feature_importances)\n",
    "    \n",
    "    return rlr_train, preprocessor, features_selected, cont_features_selected, cat_features_selected, output_string\n",
    "\n",
    "rlr_training = interactive(train_logit, \n",
    "                           {'manual' : True, 'manual_name' : 'Train the logit model'}, \n",
    "                           C = widgets.BoundedFloatText(value=1, \n",
    "                                                        min=.000001,\n",
    "                                                        max=2000, \n",
    "                                                        step=.1, \n",
    "                                                        description=\"Regularization Parameter (C) (between .00001 and 2000):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False))\n",
    "display(rlr_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Does the logistic regression make sense? What actions would you take as Carvana based on the coefficients that you see?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A decision tree is a flowchart-like structure in which each internal node represents a \"test\" on an attribute (e.g. whether a car is american or not), each branch represents the outcome of the test, and each leaf node represents a class label (decision taken after computing all attributes). The paths from root to leaf represent classification rules.\n",
    "\n",
    "<img src=\"images/Simple_Decision_Tree.png\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A decision tree is commonly used in data science because it can capture non-linear relationships (relationships that can't be captured by a straight line or a logistic regression). It works by building what amounts to a flow chart and as it looks at a data point, it works it's way down the flow chart until it gets to a \"leaf\" (a point where it can't go any further), and then it labels the point based on whatever label has the most values in the final node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A decision tree is tuned with *min_samples_split*. This is a paramater that controls how many samples must be in a leaf before it can split. If you set it to 2, then 2 samples are required in any node for that node to be split on. This means that every single leaf can correspond to a single sample, since the preceeding node split 2 into 1. How might this memorize the data and lead to overfitting? If you set it to 20, once a node has fewer than 20 samples in it, no more splits will occur. The smaller you set min_samples_split, the deeper the fitted tree you get.\n",
    "\n",
    "The other parameter that we will tune is by setting the *max_depth* of the tree. This is how many levels the tree can have (alternatively how many times it can split in any given path in the tree). The deeper the tree, the more powerful the tree, but also the more likely you are to overfit. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "294e4992ee804d888f79a83bf3fbc7c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=2, description='Regularization Parameter (min_samples_split) (betwe"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_dt(min_samples_split, max_depth):\n",
    "    print(\"Training the model, this could take a little bit of time...\")\n",
    "    X_train = feature_selection.result[2]\n",
    "    X_test = feature_selection.result[3]\n",
    "    y_train = feature_selection.result[4]\n",
    "    y_test = feature_selection.result[5]\n",
    "    cont_features_selected = feature_selection.result[6]\n",
    "    cat_features_selected = feature_selection.result[7]\n",
    "    features_selected = feature_selection.result[0]\n",
    "    preprocessor = feature_selection.result[1]\n",
    "    algorithm_starts = time.time()\n",
    "    dt_model = DecisionTreeClassifier(min_samples_split=min_samples_split, max_depth=max_depth, random_state=201)\n",
    "    dt_train = dt_model.fit(X_train, y_train)\n",
    "    training_time = time.time() - algorithm_starts\n",
    "    \n",
    "    dt_test_prob = pd.DataFrame(dt_train.predict_proba(X_test))[1]\n",
    "    dt_train_prob = pd.DataFrame(dt_train.predict_proba(X_train))[1]\n",
    "    \n",
    "    output_string = \"For the Decision Tree, the continuous features chosen were: \" + str(cont_features_selected) + \\\n",
    "                    \"\\nThe categorical features chosen were: \" + str(cat_features_selected) + \\\n",
    "                    \"\\nThe min_samples_split parameter chosen was: \" + str(min_samples_split) + \\\n",
    "                    \"\\nThe max_depth parameter chosen was: \" + str(max_depth) + \"\\n\"\n",
    "    \n",
    "    print(\"Training the model took \" + \"{:.3f}\".format(training_time) + \" seconds\\n\" \n",
    "          + \"In the test set, the Gini index is \" + \"{:.5f}\".format(Kaggle_Gini_Index(dt_test_prob, y_test)) \n",
    "          + \" and in the training set it is \" + \"{:.5f}\".format(Kaggle_Gini_Index(dt_train_prob, y_train)))\n",
    "    \n",
    "    feature_importances = pd.concat([pd.DataFrame(features_selected, columns=['Variable']), \n",
    "                                     pd.DataFrame(dt_train.feature_importances_, columns=['Importance'])], axis=1\n",
    "                                   ).sort_values(by=['Importance'], ascending=False).head(10).reset_index(drop=True)\n",
    "    print(\"\\nWe can also look at the ten most important features according to the model \\n(feature importance measures the percent of variation that variable is responsible for):\")\n",
    "    display(feature_importances)\n",
    "    \n",
    "    \n",
    "    print(\"We can also visualize the decision tree by plotting out the decision it makes to classify.\")\n",
    "    print(\"Below, the node to the left is the node that satisfies the criteria in the decision tree, the node to the right fails it.\")\n",
    "    print(\"Note: Depending on how deep your tree is, the plot may be difficult to read.\")\n",
    "    plt.figure(figsize=(20,20))\n",
    "    \n",
    "    plot_tree(dt_train, feature_names=features_selected, filled=True, fontsize=12, \n",
    "              class_names=['IsGoodBuy', 'IsBadBuy'], impurity=False, proportion=True, label='none')\n",
    "    \n",
    "    return dt_train, preprocessor, features_selected, cont_features_selected, cat_features_selected, output_string\n",
    "\n",
    "dt_training = interactive(train_dt, \n",
    "                           {'manual' : True, 'manual_name' : 'Train Decision Tree'}, \n",
    "                           max_depth = widgets.BoundedIntText(value=6, \n",
    "                                                        min=1,\n",
    "                                                        max=200, \n",
    "                                                        step=1, \n",
    "                                                        description=\"Depth of each tree (between 1 and 200):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False), \n",
    "                           min_samples_split = widgets.BoundedIntText(value=2, \n",
    "                                                        min=2,\n",
    "                                                        max=60000, \n",
    "                                                        step=1, \n",
    "                                                        description=\"Regularization Parameter (min_samples_split) (between 2 and 60000):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False)\n",
    "                          )\n",
    "display(dt_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Above we both plot the feature importance, and the decision tree (though it may be difficult to read based on the parameters selected). How would you use these results to avoid bad buy cars?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A random forest extends the idea of a decision tree. Instead of having a single decision tree, it fits a bunch of decision trees (introducing randomness into the fitting of each tree) and then in order to classify a point, it lets all the trees in the forest vote on the classification. This is, untuitively, trying to take advantage of the \"wisdom of crowds\" phenomenon.\n",
    "\n",
    "<img src=\"images/Random_Forest.png\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A random forest is tuned much like a decision tree. However, you also have to choose how many trees you want to have in the forest. When you have time, think about whether or not you can overfit by using too many trees. Note that since each tree is just a Decision Tree, you can definitely overfit by overfitting the individual decision trees, but can you overfit by using too many Decision Trees?\n",
    "\n",
    "Here though, the more trees you have, the longer it will take to train, so be careful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88f0a0a6787a4006bafa172e2e0c085b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=2, description='Regularization Parameter (min_samples_split) (betwe"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_rf(min_samples_split, max_depth, n_estimators):\n",
    "    print(\"Training the model, this could take a little bit of time...\")\n",
    "    X_train = feature_selection.result[2]\n",
    "    X_test = feature_selection.result[3]\n",
    "    y_train = feature_selection.result[4]\n",
    "    y_test = feature_selection.result[5]\n",
    "    cont_features_selected = feature_selection.result[6]\n",
    "    cat_features_selected = feature_selection.result[7]\n",
    "    features_selected = feature_selection.result[0]\n",
    "    preprocessor = feature_selection.result[1]\n",
    "    algorithm_starts = time.time()\n",
    "    rf_model = RandomForestClassifier(min_samples_split=min_samples_split, max_depth=max_depth, n_jobs=2, n_estimators=n_estimators, random_state=201)\n",
    "    rf_train = rf_model.fit(X_train, y_train)\n",
    "    training_time = time.time() - algorithm_starts\n",
    "    \n",
    "    rf_test_prob = pd.DataFrame(rf_train.predict_proba(X_test))[1]\n",
    "    rf_train_prob = pd.DataFrame(rf_train.predict_proba(X_train))[1]\n",
    "    \n",
    "    output_string = \"For the Random Forest, the continuous features chosen were: \" + str(cont_features_selected) + \\\n",
    "                    \"\\nThe categorical features chosen were: \" + str(cat_features_selected) + \\\n",
    "                    \"\\nThe min_samples_split parameter chosen was: \" + str(min_samples_split) + \\\n",
    "                    \"\\nThe max_depth parameter chosen was: \" + str(max_depth) + \\\n",
    "                    \"\\nThe n_estimators parameter chosen was: \" + str(n_estimators) + \"\\n\"\n",
    "    \n",
    "    print(\"Training the model took \" + \"{:.3f}\".format(training_time) + \" seconds\\n\" \n",
    "#           + \"The regularization parameter (C) is \" + str(C) + \"\\n\"\n",
    "          + \"In the test set, the Gini index is \" + \"{:.5f}\".format(Kaggle_Gini_Index(rf_test_prob, y_test)) \n",
    "          + \" and in the training set it is \" + \"{:.5f}\".format(Kaggle_Gini_Index(rf_train_prob, y_train)))\n",
    "    \n",
    "    feature_importances = pd.concat([pd.DataFrame(features_selected, columns=['Variable']), \n",
    "                                     pd.DataFrame(rf_train.feature_importances_, columns=['Importance'])], axis=1\n",
    "                                   ).sort_values(by=['Importance'], ascending=False).head(10).reset_index(drop=True)\n",
    "    print(\"\\nWe can also look at the ten most important features according to the model \\n(feature importance measures the percent of variation that variable is responsible for):\")\n",
    "    display(feature_importances)\n",
    "    \n",
    "    return rf_train, preprocessor, features_selected, cont_features_selected, cat_features_selected, output_string\n",
    "\n",
    "rf_training = interactive(train_rf, \n",
    "                           {'manual' : True, 'manual_name' : 'Train Random Forest'},\n",
    "                           max_depth = widgets.BoundedIntText(value=6, \n",
    "                                                        min=1,\n",
    "                                                        max=200, \n",
    "                                                        step=1, \n",
    "                                                        description=\"Depth of each tree (between 1 and 200):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False), \n",
    "                           min_samples_split = widgets.BoundedIntText(value=2, \n",
    "                                                        min=2,\n",
    "                                                        max=60000, \n",
    "                                                        step=1, \n",
    "                                                        description=\"Regularization Parameter (min_samples_split) (between 2 and 60000):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False),\n",
    "                           n_estimators = widgets.BoundedIntText(value=50, \n",
    "                                                        min=1,\n",
    "                                                        max=500, \n",
    "                                                        step=1, \n",
    "                                                        description=\"Number of trees in the forest (between 1 and 500):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False)\n",
    "                          )\n",
    "display(rf_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Boosted Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "A boosted trees model continues to extend on the basic decision tree. Basically, it is an iterated decision tree. First, you train a decision tree. Then you figure out what errors that decision tree made, and then train a second decision tree to correct the errors. To get your final prediction you take the prediction of the first tree and you add to it the prediction from the second tree (technically weighted by a learning rate described below). You can keep doing this as many times as you like with each iteration fixing the mistakes of the previous iterations. This concept is illustrated in the picture below where each tree (except for the first) fits the errors of the previous trees. Note that a \"tree\" here is just the step like function that predicts the variable (which is what a tree looks like when it is plotted).\n",
    "\n",
    "<img src=\"images/gradient-boosted-regression-trees-632x238.png\" width=\"800\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You still have to choose the depth of each individual tree (like in a Decision Tree), but you also have to choose a *learning_rate* parameter that determines how the trees are combined. A lower value means that the trees are combined more slowly so each individual tree contributes less to the overall outcome. So, a lower value reduces overfitting, but a too low value can underfit.\n",
    "\n",
    "You also have to choose how many iterative trees to train. This is different than the number of trees in a Random Forest. Why? Can you overfit with too many trees here?\n",
    "\n",
    "What is the relationship between these parameters? I.e., if you change the number of trees, should you also change the learning rate? Or are those parameters independent?\n",
    "\n",
    "These models are very powerful, and very easy to overfit. Pay careful attention to your test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e28f786e9ba441cbed77215c2aec82d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(BoundedIntText(value=6, description='Depth of each tree (between 1 and 200):', layout=La"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def train_xgb(max_depth, learning_rate, n_estimators):\n",
    "    print(\"Training the model, this could take a little bit of time...\")\n",
    "    X_train = feature_selection.result[2].values\n",
    "    X_test = feature_selection.result[3].values\n",
    "    y_train = feature_selection.result[4].values\n",
    "    y_test = feature_selection.result[5].values\n",
    "    cont_features_selected = feature_selection.result[6]\n",
    "    cat_features_selected = feature_selection.result[7]\n",
    "    features_selected = feature_selection.result[0]\n",
    "    preprocessor = feature_selection.result[1]\n",
    "    algorithm_starts = time.time()\n",
    "    xgb_model = XGBClassifier(max_depth=max_depth, learning_rate=learning_rate, n_estimators=n_estimators, n_jobs=2, random_state=201)\n",
    "    xgb_train = xgb_model.fit(X_train, y_train)\n",
    "    training_time = time.time() - algorithm_starts\n",
    "    \n",
    "    xgb_test_prob = pd.DataFrame(xgb_train.predict_proba(X_test))[1]\n",
    "    xgb_train_prob = pd.DataFrame(xgb_train.predict_proba(X_train))[1]\n",
    "    \n",
    "    output_string = \"For the Boosted Trees, the continuous features chosen were: \" + str(cont_features_selected) + \\\n",
    "                    \"\\nThe categorical features chosen were: \" + str(cat_features_selected) + \\\n",
    "                    \"\\nThe learning_rate parameter chosen was: \" + str(learning_rate) + \\\n",
    "                    \"\\nThe max_depth parameter chosen was: \" + str(max_depth) + \\\n",
    "                    \"\\nThe n_estimators parameter chosen was: \" + str(n_estimators) + \"\\n\"\n",
    "    \n",
    "    print(\"Training the model took \" + \"{:.3f}\".format(training_time) + \" seconds\\n\" \n",
    "          + \"In the test set, the Gini index is \" + \"{:.5f}\".format(Kaggle_Gini_Index(xgb_test_prob, y_test)) \n",
    "          + \" and in the training set it is \" + \"{:.5f}\".format(Kaggle_Gini_Index(xgb_train_prob, y_train)))\n",
    "    \n",
    "    feature_importances = pd.concat([pd.DataFrame(features_selected, columns=['Variable']), \n",
    "                                     pd.DataFrame(xgb_train.feature_importances_, columns=['Importance'])], axis=1\n",
    "                                   ).sort_values(by=['Importance'], ascending=False).head(10).reset_index(drop=True)\n",
    "    print(\"\\nWe can also look at the ten most important features according to the model \\n(feature importance measures the percent of variation that variable is responsible for):\")\n",
    "    display(feature_importances)\n",
    "    \n",
    "    return xgb_train, preprocessor, features_selected, cont_features_selected, cat_features_selected, output_string\n",
    "\n",
    "xgb_training = interactive(train_xgb, \n",
    "                           {'manual' : True, 'manual_name' : 'Train XGB'}, \n",
    "                           max_depth = widgets.BoundedIntText(value=6, \n",
    "                                                        min=1,\n",
    "                                                        max=200, \n",
    "                                                        step=1, \n",
    "                                                        description=\"Depth of each tree (between 1 and 200):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False), \n",
    "                           learning_rate = widgets.BoundedFloatText(value=1, \n",
    "                                                        min=.001,\n",
    "                                                        max=2000, \n",
    "                                                        step=.1, \n",
    "                                                        description=\"Regularization Parameter (learning_rate) (between .001 and 200):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False),\n",
    "                           n_estimators = widgets.BoundedIntText(value=50, \n",
    "                                                        min=1,\n",
    "                                                        max=500, \n",
    "                                                        step=1, \n",
    "                                                        description=\"Number of trees (between 1 and 500):\", \n",
    "                                                        style={'description_width': 'initial'},\n",
    "                                                        layout=Layout(width='500px'),\n",
    "                                                        disabled=False)\n",
    "                          )\n",
    "display(xgb_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Submitting your predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "Now that you have trained and tuned four different models, you must submit your predictions on a held out data set, called the *validation* set. This validation set is not part of your training or evaluation in any way, and you do not have the labels for this training set. So, you will not know how your chosen model does on this data set until we reveal it in class.\n",
    "\n",
    "You should pick a model that does well on your test set, not your training set (though it should also do well on that) because your test set is going to be a better proxy for the performance on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b631abb711eb44f9a3009b989db24d06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Model to submit:', layout=Layout(width='500px'), options=('Logisti"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def submit_model(model):\n",
    "    print(\"Submitting predictions...\")\n",
    "    if model == 'Logistic Regression':\n",
    "        if not rlr_training.result:\n",
    "            print(\"You have not trained a Logistic Regression model yet, train one first.\")\n",
    "            raise ValueError(\"Model not trained\")\n",
    "        fitted_model = rlr_training.result[0]\n",
    "        preprocessor = rlr_training.result[1]\n",
    "        features_selected = rlr_training.result[2]\n",
    "        model_selected_string = \"Logistic Regression was submitted.\"\n",
    "    elif model == 'Decision Tree':\n",
    "        if not dt_training.result:\n",
    "            print(\"You have not trained a Decision Tree model yet, train one first.\")\n",
    "            raise ValueError(\"Model not trained\")\n",
    "        fitted_model = dt_training.result[0]\n",
    "        preprocessor = dt_training.result[1]\n",
    "        features_selected = dt_training.result[2]\n",
    "        model_selected_string = \"Decision Tree was submitted.\"\n",
    "    elif model == 'Random Forest':\n",
    "        if not rf_training.result:\n",
    "            print(\"You have not trained a Random Forest model yet, train one first.\")\n",
    "            raise ValueError(\"Model not trained\")\n",
    "        fitted_model = rf_training.result[0]\n",
    "        preprocessor = rf_training.result[1]\n",
    "        features_selected = rf_training.result[2]\n",
    "        model_selected_string = \"Random Forest was submitted.\"\n",
    "    elif model == 'Boosted Trees':\n",
    "        if not xgb_training.result:\n",
    "            print(\"You have not trained a Boosted Trees model yet, train one first.\")\n",
    "            raise ValueError(\"Model not trained\")\n",
    "        fitted_model = xgb_training.result[0]\n",
    "        preprocessor = xgb_training.result[1]\n",
    "        features_selected = xgb_training.result[2]\n",
    "        model_selected_string = \"Boosted Trees was submitted.\"\n",
    "        \n",
    "    model_parameters_string = \"\"\n",
    "    if rlr_training.result:\n",
    "        model_parameters_string = model_parameters_string + rlr_training.result[5] + \"\\n\"\n",
    "    if dt_training.result:\n",
    "        model_parameters_string = model_parameters_string + dt_training.result[5] + \"\\n\"\n",
    "    if rf_training.result:\n",
    "        model_parameters_string = model_parameters_string + rf_training.result[5] + \"\\n\"\n",
    "    if xgb_training.result:\n",
    "        model_parameters_string = model_parameters_string + xgb_training.result[5] + \"\\n\"\n",
    "    \n",
    "    validation_df = pd.read_csv('test.csv')\n",
    "    validation_df['PurchDate'] = pd.to_datetime(validation_df['PurchDate'], format='%m/%d/%Y')\n",
    "    validation_df['Month'] = validation_df['PurchDate'].dt.month\n",
    "    validation_df['Year'] = validation_df['PurchDate'].dt.year\n",
    "    validation_df = validation_df.drop('PurchDate', 1)\n",
    "    validation_df = validation_df.drop('RefId', 1)\n",
    "    print(\"The first 10 rows of the validation set are:\")\n",
    "    display(validation_df.head(10))\n",
    "    validation_df.shape\n",
    "    X = preprocessor.transform(validation_df)\n",
    "    prediction = pd.DataFrame(fitted_model.predict_proba(X), columns=['ProbIsGoodBuy', 'ProbIsBadBuy'])\n",
    "    print(\"Your first 10 predictions for the validation set are:\")\n",
    "    display(prediction.head(10))\n",
    "    subpath_to_submission = \"\"\n",
    "    prediction['ProbIsBadBuy'].to_csv(subpath_to_submission + \"submission.csv\", index=False, header=False)\n",
    "    with open(subpath_to_submission + \"model_description.txt\", \"w\") as file:\n",
    "        file.write(model_parameters_string)\n",
    "        file.write(model_selected_string)\n",
    "        \n",
    "    model_dump = [preprocessor, fitted_model]\n",
    "    with open(\"model.dump\", 'wb') as f:\n",
    "        dill.dump(model_dump, f)\n",
    "    \n",
    "    print(\"Predictions submitted!\")\n",
    "    \n",
    "    return \n",
    "\n",
    "model_submission = interactive(submit_model, \n",
    "                           {'manual' : True, 'manual_name' : 'Submit Model'}, \n",
    "                           model = widgets.Dropdown(options=['Logistic Regression', 'Decision Tree', 'Random Forest', 'Boosted Trees'],\n",
    "                                                   description='Model to submit:',\n",
    "                                                   style={'description_width': 'initial'},\n",
    "                                                   layout=Layout(width='500px'),\n",
    "                                                   disabled=False),\n",
    "                          )\n",
    "display(model_submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "After you have submitted your model, you will need to \"Log Out\". This lets Amazon Web Services know that you no longer need your virtual machine, and it can be shut down. This will allow us to save money by not paying for machines that have not been shut down. We would ask that everytime you are finished, that you always ensure you log out. If you are unsure whether or not you did, you can log back in and log out again.\n",
    "\n",
    "To log out, click \"File -> Log Out\" (as shown in the image below). You will know that you have successfully logged out becuase it will take you back to the login page.\n",
    "\n",
    "<img src=\"images/Log Out.png\" width=\"800\"/>\n",
    "\n",
    "We appreciate your help in stewarding UVA's resources!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
